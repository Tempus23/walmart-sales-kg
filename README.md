# ğŸ“ˆ PronÃ³stico de Demanda para Retail (Walmart Sales Forecasting)

![Python](https://img.shields.io/badge/Python-3.11-blue)
![LightGBM](https://img.shields.io/badge/LightGBM-Enabled-brightgreen)
![License](https://img.shields.io/badge/License-MIT-yellow)

Proyecto de Machine Learning para predecir la demanda semanal de ventas en tiendas Walmart, utilizando mÃºltiples algoritmos de Machine Learning y tÃ©cnicas avanzadas de IngenierÃ­a de CaracterÃ­sticas para series temporales.

## ğŸ¯ El Problema de Negocio

En el sector *retail*, un pronÃ³stico de demanda impreciso genera dos problemas costosos:

1.  **Exceso de Stock (Overstock):** Aumento de costes de almacenamiento, capital inmovilizado y, en productos frescos, un incremento directo en el **desperdicio** (merma).
2.  **Rotura de Stock (Stockout):** PÃ©rdida de ventas directas, insatisfacciÃ³n del cliente y potencial fuga a la competencia.

Este proyecto construye modelos que pronostican la demanda futura para optimizar el inventario, reducir la merma y asegurar la disponibilidad del producto.

## ğŸ’¾ Dataset

Se utilizÃ³ el dataset [Walmart Sales](https://www.kaggle.com/datasets/mikhail1681/walmart-sales) de Kaggle.

* **Periodo:** Datos histÃ³ricos de ventas semanales.
* **Volumen:** ~6,435 registros.
* **Alcance:** Ventas semanales para 45 tiendas Walmart diferentes.
* **Variables:** Store, Date, Weekly_Sales, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment.

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Python 3.11**
- **Machine Learning:** LightGBM, XGBoost, CatBoost, Random Forest, Prophet, LSTM (TensorFlow)
- **Data Processing:** Pandas, NumPy
- **Visualization:** Matplotlib, Seaborn
- **AutoML:** TPOT
- **API:** Kaggle API

## ğŸ“ Estructura del Proyecto

```
walmart-sales-kg/
â”œâ”€â”€ demand_forecasting/          # MÃ³dulo principal
â”‚   â”œâ”€â”€ trainers/               # Implementaciones de diferentes modelos
â”‚   â”‚   â”œâ”€â”€ base.py            # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ lightGBM.py        # LightGBM Trainer
â”‚   â”‚   â”œâ”€â”€ XGBoost.py         # XGBoost Trainer
â”‚   â”‚   â”œâ”€â”€ catboost.py        # CatBoost Trainer
â”‚   â”‚   â”œâ”€â”€ randomforest.py    # Random Forest Trainer
â”‚   â”‚   â”œâ”€â”€ prophet.py         # Prophet Trainer
â”‚   â”‚   â””â”€â”€ neural_network.py  # LSTM Neural Network
â”‚   â”œâ”€â”€ walmart_data.py        # Descarga y procesamiento de datos
â”‚   â”œâ”€â”€ model.py               # Utilidades de modelo
â”‚   â””â”€â”€ plotting.py            # Funciones de visualizaciÃ³n
â”œâ”€â”€ data/                       # Datos (gitignored)
â”œâ”€â”€ outputs/                    # Modelos y visualizaciones (gitignored)
â”‚   â”œâ”€â”€ models/                # Modelos guardados
â”‚   â”œâ”€â”€ plots/                 # GrÃ¡ficos generados
â”‚   â””â”€â”€ automl_pipelines/      # Pipelines de TPOT
â”œâ”€â”€ training.py                # Script principal de entrenamiento
â”œâ”€â”€ autotrain.py              # AutoML con TPOT
â”œâ”€â”€ notebook.ipynb            # Notebook exploratorio
â””â”€â”€ requirements.txt          # Dependencias
```

## ğŸš€ InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone https://github.com/Tempus23/walmart-sales-kg.git
cd walmart-sales-kg
```

2. Crea un entorno virtual:
```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
```

3. Instala las dependencias:
```bash
pip install -r requirements.txt
```

4. Configura tu API de Kaggle (opcional, si necesitas descargar datos):
   - ObtÃ©n tu `kaggle.json` desde [Kaggle Account Settings](https://www.kaggle.com/account)
   - ColÃ³calo en `~/.kaggle/kaggle.json` (Linux/Mac) o `C:\Users\<user>\.kaggle\kaggle.json` (Windows)

## ğŸ’» Uso

### Entrenamiento de Modelos

Ejecuta el script principal de entrenamiento:

```bash
python training.py
```

Este script:
- Carga y procesa los datos automÃ¡ticamente
- Genera caracterÃ­sticas de ingenierÃ­a
- Entrena el modelo seleccionado (por defecto LSTM)
- EvalÃºa el rendimiento con MAE y WMAE
- Guarda el modelo en `outputs/models/`
- Genera visualizaciones en `outputs/plots/`

### AutoML con TPOT

Para bÃºsqueda automÃ¡tica del mejor modelo:

```bash
python autotrain.py
```

### Cambiar de Modelo

En `training.py`, cambia el trainer en la lÃ­nea 59:

```python
# Opciones disponibles:
trainer = LightGBMTrainer()
trainer = XGBoostTrainer()
trainer = CatBoostTrainer()
trainer = RandomForestTrainer()
trainer = ProphetTrainer()
trainer = LSTMTrainer()
```

## ğŸ”¬ IngenierÃ­a de CaracterÃ­sticas

El proyecto implementa las siguientes caracterÃ­sticas:

### CaracterÃ­sticas Temporales
- **Month, Quarter, Year, WeekOfYear:** Componentes temporales bÃ¡sicos
- **CaracterÃ­sticas CÃ­clicas:** `MonthSin`, `MonthCos`, `WeekSin`, `WeekCos` para capturar estacionalidad

### CaracterÃ­sticas de Lag (Rezagos)
- **ventas_lag_1:** Ventas de la semana anterior
- **ventas_lag_4:** Ventas de hace 4 semanas (~1 mes)
- **ventas_lag_52:** Ventas de hace 52 semanas (~1 aÃ±o)

### Medias MÃ³viles
- **media_movil_4_semanas:** Media de las Ãºltimas 4 semanas
- **media_movil_12_semanas:** Media de las Ãºltimas 12 semanas

### Variables Externas
- Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment (del dataset original)

## ğŸ¤– Modelos Implementados

Todos los modelos heredan de `BaseModel` con interfaz comÃºn:

| Modelo | Tipo | CaracterÃ­sticas |
|--------|------|----------------|
| **LightGBM** | Gradient Boosting | RÃ¡pido, eficiente, maneja categÃ³ricas |
| **XGBoost** | Gradient Boosting | Robusto, regularizaciÃ³n avanzada |
| **CatBoost** | Gradient Boosting | Especializado en variables categÃ³ricas |
| **Random Forest** | Ensemble | Menos prone a overfitting |
| **Prophet** | Time Series | DiseÃ±ado especÃ­ficamente para series temporales |
| **LSTM** | Deep Learning | Red neuronal recurrente para secuencias |

## ğŸ“Š Resultados

Los modelos se evalÃºan con:
- **MAE (Mean Absolute Error):** Error promedio en unidades de ventas
- **WMAE (Weighted MAE):** MAE ponderado por importancia

### Visualizaciones Generadas

- `importancia_caracteristicas.png`: Importancia de cada feature en el modelo
- `predicciones_tienda_1.png`: ComparaciÃ³n predicciones vs valores reales

## ğŸ“ˆ PrÃ³ximos Pasos

- [ ] Implementar validaciÃ³n cruzada temporal
- [ ] OptimizaciÃ³n de hiperparÃ¡metros con Optuna
- [ ] Ensemble de mÃºltiples modelos
- [ ] Deploy con API REST (FastAPI)

## ğŸ‘¤ Autor

**Carlos HernÃ¡ndez MartÃ­nez**

- GitHub: [@Tempus23](https://github.com/Tempus23)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.
