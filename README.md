# ğŸ“ˆ PronÃ³stico de Demanda para Retail (Store Item Demand)

![Python](https://img.shields.io/badge/Python-3.12-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Machine Learning](https://img.shields.io/badge/ML-Demand%20Forecasting-orange.svg)
![Status](https://img.shields.io/badge/Status-Active-success.svg)

Proyecto de Machine Learning para predecir la demanda diaria de artÃ­culos (nivel SKU) en 10 tiendas diferentes, utilizando un enfoque de Gradient Boosting (LightGBM) e IngenierÃ­a de CaracterÃ­sticas de series temporales.

El notebook principal (`notebooks/notebook.ipynb`) es 100% verificable y ejecutable en Google Colab.

## ğŸ¯ El Problema de Negocio

En el sector *retail*, un pronÃ³stico de demanda impreciso genera dos problemas costosos:

1.  **Exceso de Stock (Overstock):** Aumento de costes de almacenamiento, capital inmovilizado y, en productos frescos (como en Mercadona), un incremento directo en el **desperdicio** (merma).
2.  **Rotura de Stock (Stockout):** PÃ©rdida de ventas directas, insatisfacciÃ³n del cliente y potencial fuga a la competencia.

Este proyecto construye un modelo que pronostica la demanda futura para optimizar el inventario, reducir la merma y asegurar la disponibilidad del producto.

## ğŸ’¾ Dataset

Se utilizÃ³ el dataset [Store Item Demand Forecasting Challenge](https://www.kaggle.com/c/store-item-demand-forecasting-challenge) de Kaggle.

* **Periodo:** 5 aÃ±os de datos (2013 - 2017).
* **Volumen:** ~913,000 registros.
* **Alcance:** Ventas diarias para 50 artÃ­culos (SKUs) en 10 tiendas diferentes.

## ğŸš€ CaracterÃ­sticas Principales

- âœ… **MÃºltiples Modelos**: ImplementaciÃ³n de 6 algoritmos diferentes (LightGBM, XGBoost, CatBoost, Random Forest, Prophet, LSTM)
- âœ… **IngenierÃ­a de CaracterÃ­sticas**: Features avanzadas de series temporales (lags, medias mÃ³viles, codificaciÃ³n cÃ­clica)
- âœ… **AutoML**: BÃºsqueda automÃ¡tica de pipelines con TPOT
- âœ… **Visualizaciones**: GrÃ¡ficos de predicciones e importancia de caracterÃ­sticas
- âœ… **Arquitectura Modular**: CÃ³digo organizado y extensible

## ğŸ› ï¸ Stack TecnolÃ³gico

### Lenguaje
- **Python 3.12**

### LibrerÃ­as de Machine Learning
- **LightGBM**: Gradient Boosting principal
- **XGBoost**: Gradient Boosting alternativo
- **CatBoost**: Boosting optimizado para categÃ³ricas
- **Scikit-learn**: MÃ©tricas y utilidades ML
- **Prophet**: Modelo de series temporales de Facebook
- **TensorFlow**: Redes neuronales (LSTM)
- **TPOT**: AutoML para optimizaciÃ³n de pipelines

### AnÃ¡lisis de Datos y VisualizaciÃ³n
- **Pandas**: ManipulaciÃ³n de datos
- **NumPy**: Operaciones numÃ©ricas
- **Matplotlib**: Visualizaciones
- **Seaborn**: Visualizaciones estadÃ­sticas

### Otros
- **Kaggle**: API para descarga de datos

## ğŸ“¦ InstalaciÃ³n

### Prerrequisitos
- Python 3.12 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/Tempus23/walmart-sales-kg.git
cd walmart-sales-kg
```

2. **Crear un entorno virtual (recomendado)**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar Kaggle API (para descargar datos)**

Descarga tu archivo `kaggle.json` desde [Kaggle Account Settings](https://www.kaggle.com/account) y colÃ³calo en:
- Linux/Mac: `~/.kaggle/kaggle.json`
- Windows: `C:\Users\<Usuario>\.kaggle\kaggle.json`

AsegÃºrate de que tiene los permisos correctos:
```bash
chmod 600 ~/.kaggle/kaggle.json
```

## ğŸ’» Uso

### Entrenar un Modelo

Para entrenar un modelo con LightGBM (o cambiar a otro modelo como XGBoost, CatBoost, etc.):

```bash
python training.py
```

El script `training.py` realiza:
1. Carga y preprocesamiento de datos
2. CreaciÃ³n de caracterÃ­sticas de series temporales
3. DivisiÃ³n de datos en entrenamiento/validaciÃ³n
4. Entrenamiento del modelo
5. EvaluaciÃ³n y cÃ¡lculo de mÃ©tricas
6. Guardado del modelo entrenado
7. GeneraciÃ³n de visualizaciones

### AutoML con TPOT

Para buscar automÃ¡ticamente el mejor pipeline:

```bash
python autotrain.py
```

Este proceso puede tardar considerable tiempo dependiendo de la configuraciÃ³n de `generations` y `population_size`.

### Explorar el Notebook

El notebook Jupyter con anÃ¡lisis exploratorio y experimentaciÃ³n estÃ¡ disponible en:

```bash
jupyter notebook notebooks/notebook.ipynb
```

## ğŸ“ Estructura del Proyecto

```
walmart-sales-kg/
â”œâ”€â”€ demand_forecasting/          # Paquete principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                 # Funciones de modelo y decoradores
â”‚   â”œâ”€â”€ walmart_data.py          # Cargador de datos y feature engineering
â”‚   â”œâ”€â”€ plotting.py              # Funciones de visualizaciÃ³n
â”‚   â””â”€â”€ trainers/                # Implementaciones de modelos
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py              # Clase base abstracta
â”‚       â”œâ”€â”€ lightGBM.py          # Modelo LightGBM
â”‚       â”œâ”€â”€ XGBoost.py           # Modelo XGBoost
â”‚       â”œâ”€â”€ catboost.py          # Modelo CatBoost
â”‚       â”œâ”€â”€ randomforest.py      # Modelo Random Forest
â”‚       â”œâ”€â”€ prophet.py           # Modelo Prophet
â”‚       â””â”€â”€ neural_network.py    # Modelo LSTM
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â””â”€â”€ notebook.ipynb           # Notebook principal
â”œâ”€â”€ data/                        # Datos (no incluidos en repo)
â”œâ”€â”€ outputs/                     # Salidas del entrenamiento
â”‚   â”œâ”€â”€ models/                  # Modelos guardados
â”‚   â”œâ”€â”€ plots/                   # Visualizaciones
â”‚   â””â”€â”€ automl_pipelines/        # Pipelines de TPOT
â”œâ”€â”€ training.py                  # Script de entrenamiento principal
â”œâ”€â”€ autotrain.py                 # Script de AutoML
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ RESULTS.md                   # Resultados y mÃ©tricas detalladas
â””â”€â”€ LICENSE                      # Licencia MIT
```

## ğŸ“Š Resultados

Para ver resultados detallados, mÃ©tricas y anÃ¡lisis de los modelos, consulta el archivo [RESULTS.md](RESULTS.md).

### MÃ©tricas Principales
- **MAE (Mean Absolute Error)**: Error absoluto medio
- **WMAE (Weighted MAE)**: Error absoluto medio ponderado

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar el Modelo

En `training.py`, modifica la lÃ­nea donde se instancia el trainer:

```python
# Cambiar de LSTMTrainer a otro modelo:
trainer = LightGBMTrainer()    # LightGBM
# trainer = XGBoostTrainer()   # XGBoost
# trainer = CatBoostTrainer()  # CatBoost
# trainer = RandomForestTrainer()  # Random Forest
# trainer = ProphetTrainer()   # Prophet
```

### Ajustar CaracterÃ­sticas

Edita las listas `CARACTERISTICAS` y `CARACTERISTICAS_CATEGORICAS` en `training.py` para experimentar con diferentes conjuntos de features.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¤ Autor

**Carlos HernÃ¡ndez MartÃ­nez**

## ğŸ™ Agradecimientos

- Dataset proporcionado por [Kaggle](https://www.kaggle.com/c/store-item-demand-forecasting-challenge)
- InspiraciÃ³n en casos de uso reales del sector retail

---

â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub!
