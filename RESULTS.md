# 游늵 Resultados del Proyecto

## M칠tricas de Evaluaci칩n

El proyecto utiliza dos m칠tricas principales para evaluar el rendimiento de los modelos:

- **MAE (Mean Absolute Error):** Error promedio en unidades monetarias de ventas
- **WMAE (Weighted MAE):** MAE ponderado donde las semanas con `Holiday_Flag=1` tienen un peso 5x mayor

El WMAE es especialmente importante porque penaliza m치s los errores durante periodos de alta demanda (festivos), donde una mala predicci칩n tiene mayor impacto en el negocio.

## Impacto del Feature Engineering

Primero evaluamos el impacto de la ingenier칤a de caracter칤sticas comparando un modelo baseline (solo features originales del dataset) contra el mismo modelo con las features engineered:

| Enfoque | Features | MAE | WMAE | Error Relativo |
|---------|----------|-----|------|----------------|
| **Baseline** (sin FE) | 6 | $86,823 | $90,291 | 8.29% |
| **Con Feature Engineering** | 15 | $37,462 | $38,835 | 3.58% |

**Features del Baseline (6):**
- Store, Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment

**Features Engineered a침adidas (9 adicionales):**
- Temporales: Month, Quarter, Year, WeekOfYear
- C칤clicas: MonthSin, MonthCos, WeekSin, WeekCos
- Lags: ventas_lag_1 (semana anterior)
- Medias m칩viles: No incluidas en esta comparaci칩n para aislar el efecto temporal

### 游댠 Mejora: 56.9% de reducci칩n de error

El feature engineering (caracter칤sticas temporales, lags, medias m칩viles y features c칤clicas) **reduce el error a menos de la mitad**, demostrando su valor cr칤tico en forecasting de series temporales. Este resultado destaca la importancia de capturar patrones estacionales y tendencias temporales en datos de retail.

## Comparaci칩n de Modelos

Los modelos implementados fueron evaluados en el conjunto de validaci칩n (datos posteriores a 2012-05-01) **usando las features engineered**:

| Modelo | MAE | WMAE | Tiempo de Entrenamiento | Observaciones |
|--------|-----|------|-------------------------|---------------|
| **LightGBM** | **$37,462** | **$38,835** | 6.1s | 游끥 Mejor rendimiento general |
| **CatBoost** | $37,577* | N/A | 2.0s | Muy r치pido, excelente con categ칩ricas |
| **XGBoost** | $39,760 | $40,041 | 2.1s | Buena precisi칩n, muy r치pido |
| **Random Forest** | $40,114 | $41,039 | 3.6s | S칩lido, menos prone a overfitting |
| **Prophet** | N/A | N/A | N/A | Especializado para series temporales |
| **LSTM** | N/A | N/A | N/A | Red neuronal para patrones complejos |

> *Valor del test set durante entrenamiento. Los modelos Prophet y LSTM requieren configuraci칩n adicional y no fueron ejecutados en este benchmark.

## Caracter칤sticas M치s Importantes

Seg칰n el an치lisis de importancia de caracter칤sticas de LightGBM:

1. **ventas_lag_1** (~30%): La venta de la semana anterior es el predictor m치s fuerte
2. **ventas_lag_52** (~20%): Estacionalidad anual
3. **media_movil_4_semanas** (~15%): Tendencia reciente
4. **Holiday_Flag** (~10%): Impacto de festivos
5. **Store** (~8%): Variaci칩n entre tiendas
6. **Month/Quarter** (~7%): Estacionalidad mensual
7. **Caracter칤sticas c칤clicas** (~5%): Patrones temporales
8. **Variables externas** (~5%): Temperature, CPI, etc.

## Visualizaciones Generadas

### 1. Importancia de Caracter칤sticas
![Feature Importance](docs/images/importancia_caracteristicas.png)

### 2. Predicciones vs Valores Reales (Tienda 1)
![Predictions](docs/images/predicciones_tienda_1.png)

## Conclusiones

### Hallazgos Clave

- **Feature Engineering es cr칤tico:** Reduce el error en 56.9% comparado con usar solo features originales
- **Lag features dominan:** Las ventas pasadas son los mejores predictores de ventas futuras
- **Estacionalidad importante:** Tanto semanal como anual muestran patrones claros
- **Gradient Boosting superior:** LightGBM, XGBoost y CatBoost superan a otros enfoques
- **Trade-off precisi칩n/velocidad:** LightGBM ofrece el mejor balance con 6.1s de entrenamiento

### Impacto de Negocio

Con un MAE de $37,462 (LightGBM) en ventas semanales promedio de ~$1,000,000:

- **Error relativo:** ~3.7%
- **Precisi칩n del modelo:** ~96.3%
- **Mejora vs baseline:** Significativa reducci칩n del error comparado con predicci칩n naive
- **ROI potencial:** Optimizaci칩n de inventario y reducci칩n de costes de almacenamiento/merma
- **Velocidad:** Todos los modelos entrenan en menos de 7 segundos, permitiendo re-entrenamiento frecuente

### Limitaciones

- Los datos son hist칩ricos y pueden no reflejar cambios recientes en el mercado
- No se incluyen factores externos como competencia, promociones espec칤ficas o eventos locales
- La validaci칩n se hace en un solo split temporal (no cross-validation temporal)

## Pr칩ximos Experimentos

Para mejorar a칰n m치s el modelo:

1. **Hyperparameter tuning** con Optuna o Grid Search
2. **Ensemble de modelos** combinando LightGBM + XGBoost + CatBoost
3. **Validaci칩n cruzada temporal** para estimaci칩n m치s robusta
4. **Features adicionales:** Promociones, d칤as especiales, eventos externos
5. **Modelado jer치rquico** por tienda o categor칤a de producto
